{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from neural_net import prepare_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading samples from datasets/test_merged.samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 6675.64it/s]\n"
     ]
    }
   ],
   "source": [
    "batches, num_samples, batch_size = prepare_training_data(\"datasets/test_merged.samples\", batch_size=20, sample_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 40, 40])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = batches[0]\n",
    "first_batch_data = first_batch[0]\n",
    "\n",
    "# Crop the 48x48 image to a 40x40 image\n",
    "first_batch_data = first_batch_data[:, :, 4:44, 4:44]\n",
    "first_batch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1367, 0.1290, 0.1449, 0.1651, 0.1324, 0.1399, 0.1521],\n",
       "        [0.1448, 0.1314, 0.1391, 0.1710, 0.1180, 0.1354, 0.1603],\n",
       "        [0.1214, 0.1787, 0.1056, 0.1787, 0.1020, 0.1527, 0.1609],\n",
       "        [0.1213, 0.1399, 0.0861, 0.1579, 0.1547, 0.1533, 0.1868],\n",
       "        [0.1275, 0.1525, 0.1360, 0.1245, 0.1291, 0.1561, 0.1742],\n",
       "        [0.1235, 0.1507, 0.1598, 0.1834, 0.1116, 0.1085, 0.1625],\n",
       "        [0.1181, 0.1359, 0.1297, 0.1638, 0.1164, 0.1402, 0.1959],\n",
       "        [0.1507, 0.1402, 0.1603, 0.1190, 0.1387, 0.1374, 0.1537],\n",
       "        [0.1666, 0.1333, 0.1401, 0.1242, 0.1160, 0.1269, 0.1929],\n",
       "        [0.1701, 0.0906, 0.1588, 0.2449, 0.1103, 0.1132, 0.1122],\n",
       "        [0.1463, 0.1395, 0.1227, 0.1646, 0.1436, 0.1243, 0.1590],\n",
       "        [0.1428, 0.1398, 0.1377, 0.1544, 0.1440, 0.1330, 0.1484],\n",
       "        [0.1659, 0.1288, 0.1375, 0.1496, 0.1037, 0.1341, 0.1804],\n",
       "        [0.1325, 0.1520, 0.1322, 0.1585, 0.1092, 0.1540, 0.1616],\n",
       "        [0.1212, 0.1474, 0.1070, 0.1631, 0.1334, 0.1568, 0.1711],\n",
       "        [0.1448, 0.1571, 0.1154, 0.1069, 0.1309, 0.1489, 0.1960],\n",
       "        [0.1754, 0.1281, 0.1137, 0.1970, 0.1004, 0.1273, 0.1581],\n",
       "        [0.1391, 0.1138, 0.1246, 0.1881, 0.1533, 0.1514, 0.1297],\n",
       "        [0.1586, 0.1311, 0.1309, 0.1558, 0.1229, 0.1623, 0.1384],\n",
       "        [0.1702, 0.1103, 0.1685, 0.1571, 0.1247, 0.1238, 0.1455]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(2048, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(4096, 7),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "net(first_batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cicil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9928/1798834967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m A = torch.Tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not ellipsis"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.Tensor([[0., 0., 0., 0, 0., 0., 0.],\n",
    "        [0., 0., 0., 0, 0., 1., 0.],\n",
    "        [1., 0., 0., 0, 0., 0., 0.],\n",
    "        [0., 0., 0., 0, 0., 1., 0.],\n",
    "        [0., 0., 0., 0, 0., 0., 1.],\n",
    "        [1., 0., 0., 0, 0., 0., 0.]])\n",
    "B = torch.Tensor([[0.1551, 0.1219, 0.1731, 0, 0.1435, 0.1675, 0.1079],\n",
    "        [0.1706, 0.1421, 0.2023, 0, 0.0957, 0.1461, 0.1250],\n",
    "        [0.1874, 0.1356, 0.1399, 0, 0.1231, 0.1484, 0.1268],\n",
    "        [0.1834, 0.1347, 0.1534, 0, 0.1236, 0.1333, 0.1623],\n",
    "        [0.1741, 0.1233, 0.1431, 0, 0.1356, 0.1872, 0.1099],\n",
    "        [0.1623, 0.1737, 0.1519, 0, 0.1051, 0.1681, 0.1254]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9068dd35f1c0cd29b17cc748f99d9da10bc3e2817306717532451a6caace776c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
